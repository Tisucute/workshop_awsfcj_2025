[
{
	"uri": "//localhost:1313/",
	"title": "Building an Automated Real-Time Data Processing and Visualization Architecture on AWS",
	"tags": [],
	"description": "",
	"content": "Building an Automated Real-Time Data Processing and Visualization Architecture on AWS Author: Nguyễn Ngọc Anh Thư\nStudent ID: 22133059\nEmail: ngocanhthugialai@gmail.com\nUniversity: Ho Chi Minh City University of Technology and Education (HCMUTE)\nOverview The project \u0026ldquo;Building an Automated Processing and Real-time Data Visualization Architecture on AWS\u0026rdquo; represents my dedication and effort to develop a comprehensive system that automates the collection, processing, and visualization of real-time data streams using Amazon Web Services (AWS). With the aim of meeting the increasing demand for timely analysis and decision-making based on the latest data, the system is designed to include key components: weather data collection from OpenWeather API using Python and storage in AWS S3; orchestration managed by Amazon Managed Workflows for Apache Airflow (MWAA); data processing and transformation using AWS Glue; data storage in AWS Redshift warehouse; and finally, visualization of results through AWS QuickSight on an intuitive dashboard.\nInfrastructure deployment is implemented through Infrastructure as Code (IaC) using AWS CloudFormation, ensuring consistency, automation, ease of management, and scalability for future resource changes or additions. Security policies and access management are also configured through AWS IAM and a secure Virtual Private Cloud (VPC) environment to ensure system safety.\nI genuinely hope this report not only accurately reflects my efforts but also serves as a friendly, easy-to-understand resource for students new to AWS or modern development methodologies. Through this work, I aim to convey my enthusiasm and passion for technology and support students in gaining confidence as they embark on their AWS exploration and application journey.\nImplementation Timeline Data collection: 1 day The data is only sufficient for analysis; collecting more may incur additional costs.\nExecution of steps: 2–3 hours (depending on familiarity with the tools) Contents Introduction Tools and Architecture Diagram Tools Used Architecture Diagram Steps for Automated ETL Process About Environment Files Infrastructure as Code Deployment Setting Variables, Creating Connections, and Uploading Environment ETL Execution Process Analysis and Visualization Analysis with AWS Redshift Visualization with AWS Quicksight Cleanup In Conclusion "
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduce",
	"tags": [],
	"description": "",
	"content": "\rNguyễn Ngọc Anh Thư – 22133059\rHCMC University of Technology and Education (HCMUTE)\rBuilding an Automated Real-Time Data Processing and Visualization Architecture on AWS\rThis report presents the process of building a real-time data processing and visualization system on AWS, including the following main contents:\rIntroduction: Brief overview of contents related to the topic.\rTools \u0026 Architectural Diagram: Description of AWS services, supporting tools, and the overall system architecture diagram.\rSteps to Implement the Automatic ETL Process: Detailed guidance step-by-step, from preparing the environment, deploying infrastructure, creating connections, to performing ETL.\rAnalysis \u0026 Visualization: Explanation of data analysis with AWS Redshift and dashboard creation with AWS QuickSight.\rCleaning Up Resources: Instructions for deleting AWS resources after completion to optimize costs.\rExecution Time:\rData collection: 1 day\rPerforming operations: 2 - 3 hours (depending on familiarity with the tools)\rWarning: The provided data is only sufficient for analysis; additional data may incur extra costs.\rPrerequisites:\rAn AWS account with access rights to necessary services (S3, IAM, Glue, Redshift, MWAA, QuickSight, etc.).\rPython installed along with related libraries (requests, boto3, etc.).\rStable internet connection.\rBasic knowledge of AWS and command line operations.\rEstimated Cost:Approximately from 20$ to 30$\r"
},
{
	"uri": "//localhost:1313/2-architecture/2.1-tools/",
	"title": "Tools",
	"tags": [],
	"description": "",
	"content": "1. OpenWeather API OpenWeather API is a service providing real-time weather data through RESTful endpoints. Users can retrieve information such as temperature, humidity, pressure, v.v. by sending HTTP requests and receiving data in JSON or XML format.\n2. Python Script Python is a popular programming language, powerful in data processing. In this system, Python scripts are used to:\nCall APIs (e.g.: OpenWeather API) to retrieve data.\nParse JSON data returned.\nClean and normalize data (convert time zones, rename fields, v.v.).\nExport data to formats such as CSV, Parquet, or JSON.\nPush data to Amazon S3 for storage.\n3. Amazon S3 Amazon S3 is AWS’s object storage service, allowing data storage and retrieval with high durability and scalability. In this architecture, S3 is used to:\nStore raw data generated by Python scripts.\nStore DAG definition files for Airflow.\nStore requirements.txt files to manage dependencies for Airflow.\n4. AWS Glue AWS Glue is AWS’s serverless ETL (Extract, Transform, Load) service, supporting automation of schema detection, data cleaning, transformation, and loading. Key components:\nGlue Crawler: Automatically scans data on S3, detects schema, and creates metadata tables in the Data Catalog.\nGlue ETL Job: Executes Scala or Python (Spark) code to process, transform data, and export results to S3 or Redshift.\n5. Amazon Redshift Amazon Redshift is a cloud-based data warehouse service optimized for analytical queries on large datasets (OLAP). Redshift supports storing data using star/snowflake schema models, enabling execution of complex queries with high performance, suitable for BI tasks, data analytics.\n6. Apache Airflow (MWAA) Apache Airflow is an open-source platform for scheduling, orchestrating, and monitoring complex workflows. On AWS, Airflow is provided as Managed Workflows for Apache Airflow (MWAA). Airflow uses DAGs (Directed Acyclic Graphs) to define data processing steps, supporting automation, retry, alert, and integration with multiple AWS services.\n7. Amazon QuickSight Amazon QuickSight is a Business Intelligence (BI) service on AWS, supporting connections to multiple data sources such as Redshift, S3, v.v. QuickSight enables building interactive dashboards, charts, and reports using a drag-and-drop interface, supporting data analysis and visualization for business users.\n8. AWS CloudFormation, IAM, VPC, Secrets Manager CloudFormation: Infrastructure as Code service, automating the deployment and management of AWS resources.\nIAM (Identity and Access Management): Manages access rights, authentication, and permissions for users/services.\nVPC (Virtual Private Cloud): Creates isolated virtual networks on AWS, controls access, and secures resources.\nSecrets Manager: Securely stores, manages, and retrieves sensitive information (API keys, passwords, v.v.).\n"
},
{
	"uri": "//localhost:1313/2-architecture/2.2-architecture/",
	"title": "Architecture Diagram",
	"tags": [],
	"description": "",
	"content": "Architecture Diagram This architecture describes a process for collecting, processing, storing, analyzing, and visualizing weather data using AWS services and open-source tools. Initially, users request weather information. A Python script packaged and stored within an Amazon S3 environment is automatically invoked by Apache Airflow (MWAA) according to a predefined schedule. This Python script leverages PySpark (Spark integrated directly into the Python script) to call the OpenWeather API, retrieve real-time weather data, perform preliminary processing, and store the raw data into an Amazon S3 bucket. Subsequently, AWS Glue Jobs perform advanced ETL tasks, cleaning and normalizing the data before loading it into Amazon Redshift for deeper analysis. Amazon QuickSight then connects to Redshift to build interactive dashboards, enabling users to visualize and easily analyze data to make informed decisions.\nThe entire infrastructure and services are automatically managed and deployed through AWS CloudFormation, secured by AWS IAM, VPC, and Secrets Manager, ensuring controlled access and secure storage of sensitive information within the system.\nThe diagram below illustrates the overall system architecture on AWS: "
},
{
	"uri": "//localhost:1313/2-architecture/",
	"title": "Tools and Architecture",
	"tags": [],
	"description": "",
	"content": "2.1 Tools Used\n2.2 Architecture Diagram\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]