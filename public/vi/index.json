[
{
	"uri": "//localhost:1313/vi/",
	"title": "Thiết kế và Triển khai Data Pipeline trên nền tảng AWS Cloud",
	"tags": [],
	"description": "",
	"content": "Thiết kế và Triển khai Data Pipeline trên nền tảng AWS Cloud Tổng quan Trong bài lab này, bạn sẽ tìm hiểu các khái niệm cơ bản và thực hành về AWS Cloud.\nNội dung Giới thiệu Sơ đồ Kiến trúc Giới thiệu tập dữ liệu Chuẩn bị môi trường AWS Ingest dữ liệu vào S3 Xử lý và chuyển đổi dữ liệu với Glue Tự động hóa pipeline với Lambda \u0026amp; Step Functions Nạp dữ liệu vào Redshift Trực quan hóa với QuickSight Giám sát, bảo mật và tối ưu Xóa tài nguyên AWS sau khi hoàn thành Tổng kết và mở rộng "
},
{
	"uri": "//localhost:1313/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "\rNguyễn Ngọc Anh Thư – 22133059\rTrường Đại học Sư phạm Kỹ thuật TP. Hồ Chí Minh\rThiết kế và Triển khai Data Pipeline dữ liệu thời tiết trên AWS Cloud\rTrong kỷ nguyên dữ liệu, việc thu thập, xử lý và phân tích dữ liệu thời gian thực đóng vai trò then chốt trong việc ra quyết định. Đề tài “Thiết kế và Triển khai Data Pipeline dữ liệu thời tiết trên nền tảng AWS Cloud” được thực hiện nhằm xây dựng một quy trình tự động, linh hoạt để:\rThu thập dữ liệu thời tiết thực từ OpenWeather API bằng Python.\rLưu trữ dữ liệu thô vào Amazon S3 theo kiến trúc Data Lake.\rXử lý và chuyển đổi dữ liệu tự động với AWS Glue.\rNạp dữ liệu đã biến đổi vào Amazon Redshift để phục vụ phân tích OLAP.\rTruy vấn ad-hoc trên S3 với AWS Athena và trực quan hóa kết quả trên AWS QuickSight.\rQuản lý workflow bằng Apache Airflow, chạy các DAG thu thập – xử lý – nạp dữ liệu, với file cấu hình phụ thuộc (requirements.txt).\rMục tiêu của đề tài:\rHiểu và vận dụng kiến trúc Data Lake \u0026 Data Warehouse trên AWS.\rThực hành xây dựng ETL/ELT pipeline tự động, có khả năng mở rộng.\rÁp dụng công cụ phân tích và trực quan hóa dữ liệu thời gian thực.\r"
},
{
	"uri": "//localhost:1313/vi/2-architecture/2.1-tools/",
	"title": "Các công cụ được sử dụng",
	"tags": [],
	"description": "",
	"content": "Các công cụ được sử dụng 1. Data Ingestion OpenWeather API: Nguồn dữ liệu thời tiết thời gian thực (temperature, humidity, v.v.) qua RESTful endpoint. Python Script: Gọi API, parse JSON, làm sạch sơ bộ (ví dụ: chuyển timezone, chuẩn hoá tên trường…) Xuất file (CSV/Parquet/JSON) và ghi lên Amazon S3. 2. Staging \u0026amp; Storage Amazon S3 Bucket: Raw zone: chứa file thô do Python script tạo. /dags: nơi lưu definition của Airflow DAGs. requirements.txt: liệt kê dependencies (requests, boto3, pandas…) để Airflow tự động cài trước khi chạy task. 3. Transformation AWS Glue: Glue Crawler (tuỳ chọn): tự động phát hiện schema từ file raw trên S3 và tạo table metadata trong Data Catalog. Glue ETL Job: chạy Scala/Python Spark để: Đọc dữ liệu từ S3 (raw) Làm sạch/biến đổi (ví dụ: filter records, join thêm lookup table, enrichment…) Xuất dữ liệu đã transform sang S3 clean zone hoặc trực tiếp load vào Redshift. 4. Data Warehouse Amazon Redshift Cluster: Lưu trữ bảng đã qua xử lý (dim, fact) theo mô hình star/snowflake schema. Hỗ trợ query phân tích khối lượng lớn với hiệu năng cao. 5. Orchestration Apache Airflow: Scheduler \u0026amp; Web UI: lên lịch (cron, interval), trigger manual, monitoring, retry, alert khi có lỗi. DAGs (viết bằng Python): định nghĩa luồng công việc. PythonOperator: chạy script ingestion. GlueJobOperator: khởi job AWS Glue. RedshiftOperator hoặc PostgresOperator: chạy SQL trên Redshift nếu cần. Triển khai code lên Airflow bằng cách mount folder /dags từ S3 và requirements.txt để quản lý dependencies. 6. Analyze AWS Athena: Cho phép query trực tiếp file dữ liệu trên S3 (clean zone) bằng SQL mà không cần load vào database. Amazon QuickSight: Kết nối đến Redshift (hoặc Athena) để dựng dashboard, chart, alert; cung cấp giao diện drag-and-drop cho business – Gọi API, parse JSON, làm sạch sơ bộ (ví dụ: chuyển timezone, chuẩn hoá tên trường…) – Xuất file (CSV/Parquet/JSON) và ghi lên Amazon S3. "
},
{
	"uri": "//localhost:1313/vi/2-architecture/",
	"title": "Kiến trúc",
	"tags": [],
	"description": "",
	"content": "Kiến trúc "
},
{
	"uri": "//localhost:1313/vi/2-architecture/2.2-architecture/",
	"title": "Xây dựng Sơ đồ Kiến trúc",
	"tags": [],
	"description": "",
	"content": "Sơ đồ Kiến trúc Pipeline trên AWS Cloud tự động thu thập dữ liệu từ OpenWeather API bằng Python và lưu vào S3, sau đó AWS Glue làm sạch và chuyển đổi dữ liệu trước khi nạp vào Redshift theo star-schema; Amazon Athena và QuickSight phục vụ phân tích ad-hoc và trực quan hóa, còn Apache Airflow điều phối toàn bộ quy trình với retry, logging và khả năng mở rộng linh hoạt. Sơ đồ dưới đây minh họa tổng thể kiến trúc hệ thống trên AWS: "
},
{
	"uri": "//localhost:1313/vi/3-data/",
	"title": "Tập dữ liệu được sử dụng",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về tập dữ liệu lấy từ OpenWeather API Tập dữ liệu thu thập từ OpenWeather API là một chuỗi thời gian (time-series) các bản ghi thời tiết, mỗi bản ghi tương ứng với một thời điểm quan sát tại một vị trí địa lý cụ thể. Bộ dữ liệu này rất phù hợp cho các bài toán phân tích biến động khí hậu, dự báo thời tiết, trực quan hóa dashboard hoặc xây dựng mô hình máy học.\nCác trường dữ liệu chính gồm:\nThông tin chung:\ndt: Thời điểm quan sát (UNIX timestamp) timezone: Độ lệch múi giờ so với UTC id, name: Mã và tên thành phố Vị trí địa lý:\ncoord.lat, coord.lon: Vĩ độ, kinh độ Thông số thời tiết chính (main):\ntemp: Nhiệt độ trung bình feels_like: Cảm giác nhiệt độ temp_min, temp_max: Nhiệt độ cực tiểu/cực đại pressure: Áp suất khí quyển humidity: Độ ẩm Thời tiết chi tiết (weather - mảng):\nmain: Mô tả ngắn (ví dụ: \u0026ldquo;Clear\u0026rdquo;, \u0026ldquo;Rain\u0026rdquo;) description: Mô tả chi tiết hơn icon: Mã icon hiển thị Gió:\nwind.speed: Tốc độ gió (m/s) wind.deg: Hướng gió (độ) Mây:\nclouds.all: Phần trăm che phủ mây Tầm nhìn:\nvisibility: Tầm nhìn (mét) Lượng mưa/tuyết (nếu có):\nrain.1h, rain.3h: Lượng mưa trong 1h/3h snow.1h, snow.3h: Lượng tuyết trong 1h/3h Thời điểm mặt trời mọc/lặn:\nsys.sunrise, sys.sunset: Thời điểm mặt trời mọc/lặn (UNIX timestamp) Lưu ý:\nDữ liệu thường được thu thập định kỳ (ví dụ mỗi 15–60 phút), lưu dưới dạng JSON gốc hoặc chuyển thành bảng CSV với các\n"
},
{
	"uri": "//localhost:1313/vi/6-cleanup/",
	"title": "Dọn dẹp tài nguyên  ",
	"tags": [],
	"description": "",
	"content": "Chúng ta sẽ tiến hành các bước sau để xóa các tài nguyên chúng ta đã tạo trong bài thực hành này.\nXóa EC2 instance Truy cập giao diện quản trị dịch vụ EC2 Click Instances. Click chọn cả 2 instance Public Linux Instance và Private Windows Instance. Click Instance state. Click Terminate instance, sau đó click Terminate để xác nhận. Truy cập giao diện quản trị dịch vụ IAM Click Roles. Tại ô tìm kiếm , điền SSM. Click chọn SSM-Role. Click Delete, sau đó điền tên role SSM-Role và click Delete để xóa role. Click Users. Click chọn user Portfwd. Click Delete, sau đó điền tên user Portfwd và click Delete để xóa user. Xóa S3 bucket Truy cập giao diện quản trị dịch vụ System Manager - Session Manager. Click tab Preferences. Click Edit. Kéo chuột xuống dưới. Tại mục S3 logging. Bỏ chọn Enable để tắt tính năng logging. Kéo chuột xuống dưới. Click Save. Truy cập giao diện quản trị dịch vụ S3 Click chọn S3 bucket chúng ta đã tạo cho bài thực hành. ( Ví dụ : lab-fcj-bucket-0001 ) Click Empty. Điền permanently delete, sau đó click Empty để tiến hành xóa object trong bucket. Click Exit. Sau khi xóa hết object trong bucket, click Delete Điền tên S3 bucket, sau đó click Delete bucket để tiến hành xóa S3 bucket. Xóa các VPC Endpoint Truy cập vào giao diện quản trị dịch vụ VPC Click Endpoints. Chọn 4 endpoints chúng ta đã tạo cho bài thực hành bao gồm SSM, SSMMESSAGES, EC2MESSAGES, S3GW. Click Actions. Click Delete VPC endpoints. Tại ô confirm , điền delete. Click Delete để tiến hành xóa các endpoints. Click biểu tượng refresh, kiểm tra tất cả các endpoints đã bị xóa trước khi làm bước tiếp theo. Xóa VPC Truy cập vào giao diện quản trị dịch vụ VPC Click Your VPCs. Click chọn Lab VPC. Click Actions. Click Delete VPC. Tại ô confirm, điền delete để xác nhận, click Delete để thực hiện xóa Lab VPC và các tài nguyên liên quan. "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]