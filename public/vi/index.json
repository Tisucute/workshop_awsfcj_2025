[
{
	"uri": "//localhost:1313/vi/",
	"title": "Xây dựng kiến trúc xử lý tự động và trực quan hóa dữ liệu thời gian thực trên AWS",
	"tags": [],
	"description": "",
	"content": "Xây dựng kiến trúc xử lý tự động và trực quan hóa dữ liệu thời gian thực trên AWS Họ tên: Nguyễn Ngọc Anh Thư\nMSSV: 22133059\nEmail: ngocanhthugialai@gmail.com\nTrường: Đại học Sư phạm Kỹ thuật TP.HCM (HCMUTE)\nTổng quan Đề tài \u0026ldquo;Xây dựng kiến trúc xử lý tự động và trực quan hóa dữ liệu thời gian thực trên AWS\u0026rdquo; là sự tâm huyết và nỗ lực nhằm xây dựng một hệ thống toàn diện, tự động hóa việc thu thập, xử lý và hiển thị trực quan các luồng dữ liệu thời gian thực dựa trên nền tảng Amazon Web Services (AWS). Với mục tiêu đáp ứng nhu cầu phân tích và ra quyết định nhanh chóng, hiệu quả dựa trên dữ liệu mới nhất, hệ thống được thiết kế bao gồm các thành phần chính: thu thập dữ liệu thời tiết từ API của OpenWeather bằng Python và lưu trữ vào AWS S3; orchestration thông qua Amazon Managed Workflows for Apache Airflow (MWAA); xử lý và chuyển đổi dữ liệu bằng AWS Glue; lưu trữ dữ liệu vào kho dữ liệu AWS Redshift; và cuối cùng trực quan hóa kết quả bằng AWS QuickSight trên dashboard trực quan.\nViệc triển khai hạ tầng được thực hiện thông qua mã nguồn (Infrastructure as Code - IaC) sử dụng AWS CloudFormation, đảm bảo tính nhất quán, tự động hóa và dễ dàng quản lý, mở rộng khi có nhu cầu thay đổi hoặc bổ sung tài nguyên. Các chính sách bảo mật và quản lý truy cập cũng được thiết lập thông qua AWS IAM và môi trường bảo mật mạng riêng ảo (VPC) nhằm đảm bảo an toàn cho hệ thống.\nEm rất hy vọng báo cáo này không chỉ phản ánh chân thực quá trình thực hiện của em, mà còn là một tài liệu thân thiện, dễ hiểu, đồng hành cùng các bạn sinh viên mới tiếp cận AWS hoặc các mô hình phát triển hiện đại. Mong rằng, qua đây em có thể truyền tải được sự nhiệt huyết, niềm đam mê với công nghệ và hỗ trợ các bạn tự tin hơn trên hành trình khám phá và ứng dụng AWS.\nThời gian thực hiện Lấy dữ liệu: 1 ngày Dữ liệu chỉ đủ để phân tích, nếu nhiều hơn có thể phát sinh thêm nhiều chi phí\nThực hiện các thao tác: 2 - 3 tiếng (tùy vào độ quen thuộc với các công cụ) Nội dung Giới thiệu Các công cụ sử dụng và Sơ đồ kiến trúc Các công cụ sử dụng Sơ đồ kiến trúc Các bước thực hiện quá trình ETL tự động Về các file môi trường Triển khai hạ tầng bằng mã nguồn Thiết lập biến, tạo kết nối và upload môi trường Quá trình thực hiện ETL Phân tích và trực quan hóa Phân tích với AWS Redshift Trực quan hóa với AWS Quicksight Dọn dẹp tài nguyên Các lỗi có thể gặp và cách khắc phục Kết luận "
},
{
	"uri": "//localhost:1313/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "\rNguyễn Ngọc Anh Thư – 22133059\rTrường Đại học Sư phạm Kỹ thuật TP. Hồ Chí Minh\rXây dựng kiến trúc xử lý tự động và trực quan hóa dữ liệu thời gian thực trên AWS\rBáo cáo này trình bày quá trình xây dựng một hệ thống xử lý và trực quan hóa dữ liệu thời gian thực trên AWS, bao gồm các nội dung chính sau:\rGiới thiệu: Sơ lược về các nội dung liên quan tới đề tài.\rCác công cụ sử dụng \u0026 Sơ đồ kiến trúc: Trình bày các dịch vụ AWS, công cụ hỗ trợ và sơ đồ tổng thể của hệ thống.\rCác bước thực hiện quá trình ETL tự động: Hướng dẫn chi tiết từng bước từ chuẩn bị môi trường, triển khai hạ tầng, thiết lập kết nối đến thực thi ETL.\rPhân tích \u0026 trực quan hóa: Mô tả cách phân tích dữ liệu với AWS Redshift và xây dựng dashboard trực quan với AWS QuickSight.\rDọn dẹp tài nguyên: Hướng dẫn xóa các tài nguyên AWS sau khi hoàn thành để tối ưu chi phí.\rThời gian thực hiện\rLấy dữ liệu: 1 ngày\rThực hiện các thao tác: 2 - 3 tiếng (tùy vào độ quen thuộc với các công cụ)\rChú ý: Dữ liệu chỉ đủ để phân tích, nếu nhiều hơn có thể phát sinh thêm nhiều chi phí.\rĐiều kiện tiên quyết\rCó tài khoản AWS và quyền truy cập các dịch vụ cần thiết (S3, IAM, Glue, Redshift, MWAA, QuickSight,...).\rĐã cài đặt Python và các thư viện liên quan (requests, boto3,...).\rMáy tính kết nối internet ổn định.\rKiến thức cơ bản về AWS và dòng lệnh.\rKhoản phí ước tính:Trong khoảng từ 20$ tới 30$\r"
},
{
	"uri": "//localhost:1313/vi/2-architecture/2.1-tools/",
	"title": "Các công cụ được sử dụng",
	"tags": [],
	"description": "",
	"content": "1. OpenWeather API OpenWeather API là dịch vụ cung cấp dữ liệu thời tiết thời gian thực thông qua các RESTful endpoint. Người dùng có thể truy xuất các thông tin như nhiệt độ, độ ẩm, áp suất, v.v. bằng cách gửi yêu cầu HTTP và nhận về dữ liệu ở định dạng JSON hoặc XML.\n2. Python Script Python là ngôn ngữ lập trình phổ biến, mạnh mẽ trong xử lý dữ liệu. Trong hệ thống này, Python script được sử dụng để:\nGọi API (ví dụ: OpenWeather API) để lấy dữ liệu.\nPhân tích cú pháp (parse) dữ liệu JSON trả về.\nLàm sạch, chuẩn hóa dữ liệu (chuyển đổi múi giờ, đổi tên trường, v.v.).\nXuất dữ liệu ra các định dạng như CSV, Parquet, hoặc JSON.\nĐẩy dữ liệu lên Amazon S3 để lưu trữ.\n3. Amazon S3 Amazon S3 là dịch vụ lưu trữ đối tượng (object storage) của AWS, cho phép lưu trữ và truy xuất dữ liệu với độ bền và khả năng mở rộng cao. Trong kiến trúc này, S3 được dùng để:\nLưu trữ dữ liệu thô (raw data) do Python script tạo ra.\nLưu trữ các file định nghĩa DAGs cho Airflow.\nLưu trữ các file requirements.txt để quản lý dependencies cho Airflow.\n4. AWS Glue AWS Glue là dịch vụ ETL (Extract, Transform, Load) serverless của AWS, hỗ trợ tự động hóa việc phát hiện schema, làm sạch, biến đổi và nạp dữ liệu. Các thành phần chính:\nGlue Crawler: Tự động quét dữ liệu trên S3, phát hiện schema và tạo metadata table trong Data Catalog.\nGlue ETL Job: Chạy mã Scala hoặc Python (Spark) để xử lý, biến đổi dữ liệu và xuất kết quả sang S3 hoặc Redshift.\n5. Amazon Redshift Amazon Redshift là dịch vụ data warehouse trên nền tảng đám mây, tối ưu cho các truy vấn phân tích dữ liệu lớn (OLAP). Redshift hỗ trợ lưu trữ dữ liệu theo mô hình star/snowflake schema, cho phép thực hiện các truy vấn phức tạp với hiệu năng cao, phù hợp cho các bài toán BI, phân tích dữ liệu.\n6. Apache Airflow (MWAA) Apache Airflow là nền tảng mã nguồn mở dùng để lập lịch, điều phối và giám sát các workflow (luồng công việc) phức tạp. Trên AWS, Airflow được cung cấp dưới dạng dịch vụ Managed Workflows for Apache Airflow (MWAA). Airflow sử dụng các DAGs (Directed Acyclic Graphs) để định nghĩa các bước xử lý dữ liệu, hỗ trợ tự động hóa, retry, alert, và tích hợp với nhiều dịch vụ AWS.\n7. Amazon QuickSight Amazon QuickSight là dịch vụ BI (Business Intelligence) trên AWS, hỗ trợ kết nối đến nhiều nguồn dữ liệu như Redshift, S3,\u0026hellip; QuickSight cho phép xây dựng dashboard, biểu đồ, báo cáo tương tác với giao diện kéo-thả, hỗ trợ phân tích và trực quan hóa dữ liệu cho người dùng doanh nghiệp.\n8. AWS CloudFormation, IAM, VPC, Secrets Manager CloudFormation: Dịch vụ quản lý hạ tầng dưới dạng mã (Infrastructure as Code), giúp tự động hóa việc triển khai và quản lý tài nguyên AWS.\nIAM (Identity and Access Management): Quản lý quyền truy cập, xác thực và phân quyền cho người dùng/dịch vụ.\nVPC (Virtual Private Cloud): Tạo mạng ảo riêng biệt trên AWS, kiểm soát truy cập và bảo mật cho các tài nguyên.\nSecrets Manager: Lưu trữ, quản lý và truy xuất thông tin nhạy cảm (API key, mật khẩu, v.v.) một cách an toàn.\n"
},
{
	"uri": "//localhost:1313/vi/2-architecture/",
	"title": "Các công cụ sử dụng và Sơ đồ kiến trúc",
	"tags": [],
	"description": "",
	"content": "2.1 Các công cụ sử dụng\n2.2 Sơ đồ kiến trúc\n"
},
{
	"uri": "//localhost:1313/vi/2-architecture/2.2-architecture/",
	"title": "Xây dựng Sơ đồ Kiến trúc",
	"tags": [],
	"description": "",
	"content": "Sơ đồ Kiến trúc Kiến trúc này mô tả một quy trình thu thập, xử lý, lưu trữ, phân tích và trực quan hóa dữ liệu thời tiết thông qua các dịch vụ AWS và công cụ mã nguồn mở. Ban đầu, người dùng gửi yêu cầu thông tin thời tiết. Một Python script được đóng gói và lưu trữ vào môi trường Amazon S3, để Apache Airflow (MWAA) tự động gọi thực thi theo lịch định sẵn. Python script này sử dụng thư viện PySpark (Spark được tích hợp sẵn trong script Python) để gọi API của OpenWeather, lấy dữ liệu thời tiết theo thời gian thực, xử lý sơ bộ và lưu vào bucket Amazon S3 dưới dạng dữ liệu thô. Tiếp theo, AWS Glue Job tiến hành các bước ETL nâng cao, làm sạch, chuẩn hóa dữ liệu và nạp vào Amazon Redshift, sẵn sàng cho việc phân tích chuyên sâu. Sau đó, Amazon QuickSight kết nối với Redshift để tạo ra dashboard tương tác, trực quan hóa dữ liệu giúp người dùng dễ dàng phân tích và ra quyết định.\nToàn bộ hạ tầng và các dịch vụ này được quản lý và triển khai tự động bằng AWS CloudFormation, đồng thời được bảo mật chặt chẽ bởi AWS IAM, VPC và Secrets Manager, giúp kiểm soát truy cập và lưu trữ an toàn các thông tin nhạy cảm trong hệ thống.\nSơ đồ dưới đây minh họa tổng thể kiến trúc hệ thống trên AWS: "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]